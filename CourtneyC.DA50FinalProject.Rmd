---
title: "Stacked Ensemble Models for Classification of Conflicting Status of Variants0"
author: "Christopher-Courtney"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true         
    toc_float: true   
---

## Introduction:

The objective of this notebook is to analyze the [Genetic Variant Classifications](https://www.kaggle.com/datasets/kevinarvai/clinvar-conflicting)
dataset, and build an ensemble ML model capable of accurately predicting conflicting 
clinical classifications of variants using a CRISP-DM approach.

[ClinVar](https://www.ncbi.nlm.nih.gov/clinvar/) is a public database widely used
by the research and medical communities to study variant genes. User submissions 
are assigned a pathogenicity level ranging from benign to pathogenic. There are
a large number of variables involved in this assignment, currently the majority of
these are performed in the wet lab. A key problem is conflicting reports from different
labs regarding the pathogenicity of the same variant.

The ability to identify genes with conflicting pathogenicity reports allows researchers
to select genes for further characterization. Either to remove ambiguity regarding 
pathogenicity, or to avoid genes that require further research related to any
diseases of interest to the researcher.

A detailed explanation of much of the features in this dataset can be found [here](https://www.ncbi.nlm.nih.gov/clinvar/docs/help/)
Though it should be noted some of the column names are different, they contain the correct data.

## EDA:

```{r EDA.load.libraries, echo=FALSE,message = FALSE, warning=FALSE}
packages <- c("dplyr", "tidyr", "ggplot2", "psych", "caret",
              "ranger", "tidyverse", "tidymodels", "MLmetrics",
              "gridExtra", "xgboost", "glmnet", "httr","jsonlite", "pROC")

to.install <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(to.install)) install.packages(to.install)


library(dplyr)
library(tidyr)
library(tidyverse)
library(tidymodels)
library(ModelMetrics)
library(ggplot2)
library(gridExtra)
library(psych)
library(caret)
library(xgboost)
library(ranger)
library(glmnet)
library(pROC)
```




```{r github.test, echo=FALSE, message=FALSE}
# load url
url <- "https://github.com/unstoppablegiggle/ClinVarPredictionModel/raw/refs/heads/main/clinvar_conflicting.csv.zip"

# make temporary zip
zip <- tempfile(fileext = ".zip")
download.file(url, destfile = zip, mode = "wb")

# uload into df
df <- read.csv(unz(zip, "clinvar_conflicting.csv"), stringsAsFactors = T)
```
The first step is observing the general structure of the dataset.

```{r EDA.str}
str(df)
```

The data consists of `r nrow(df)` observations with a mixture of `r ncol(df)` categorical
and continuous features. The target feature CLASS is a binary feature with 0 indicating
consensus on pathogenic status of a variant and 1 indicating conflict.

There are multiple columns that appear to be unique identifiers or filled with NA
values. Several need to be relabeled as factors. CLNHGVS, and POS are unique 
identifiers and will be dropped during handling of NA.

```{r EDA.label.factors, echo = FALSE}
df$CLASS <- as.factor(df$CLASS)
df$STRAND <- as.factor(df$STRAND)
df$ORIGIN <- as.factor(df$ORIGIN)
df$BLOSUM62 <- as.factor(df$BLOSUM62)
```


```{r EDA.summary}
summary(df)
```

Multiple features have NA values or consist largely thereof. These will be imputed
or dropped on a case by case basis. Several features have high cardinality, and
will be simplified or dropped. 

Before progressing an overview of CLASS distribution will be useful.

```{r EDA.CLASS.dist, echo = FALSE}
ggplot(df, aes(x=CLASS)) +
  geom_bar() +
  theme_bw()
```

There is clearly a class imbalance, largely in favor of 0 or "no conflict". This
will be addressed using a combination of up and down sampling.

### EDA: NA and Outlier Handling

Before performing a more in depth analysis of features NA values will be dropped.
Several features have either nan, "", or NA for over half of their entries. These will
be dropped completely. Note that Intron is mostly NA because of the large number of 
variants located within exons. This information will be captured using other methods.

```{r EDA.drop.na.col}
# get NA columns
na.features <- c("CLNDISDBINCL", "CLNDNINCL", "CLNSIGINCL", "CLNVI", "SSR",
                 "INTRON", "MOTIF_NAME", "MOTIF_POS", "HIGH_INF_POS",
                 "MOTIF_SCORE_CHANGE", "DISTANCE", "BAM_EDIT", "CLNHGVS", "POS")

# Remove NA columns
df.clean <- df %>% select(-all_of(na.features))

# verify
ncol(df.clean)

summary(df.clean)
```

The dataset has been reduced from 47 to `r ncol(df.clean)` features.

Features such as SIFT and PolyPhen may have predictive power, however it will
require a relabel of the missing data and a check of the target variable's distribution
downstream.

This is shown in the table below, note entries now contain "missing".

```{r EDA.correct.missing, echo = FALSE}
df.clean$SIFT <- factor(ifelse(df.clean$SIFT == "", "missing", as.character(df.clean$SIFT)))
df.clean$PolyPhen <- factor(ifelse(df.clean$PolyPhen == "", "missing", as.character(df.clean$PolyPhen)))
df.clean$BLOSUM62 <- factor(ifelse(is.na(df.clean$BLOSUM62), "missing", df.clean$BLOSUM62)) 
df.clean$Feature_type <- factor(ifelse(df.clean$Feature_type == "", "missing", as.character(df.clean$Feature_type)))
df.clean$BIOTYPE <- factor(ifelse(df.clean$BIOTYPE      == "", "missing", as.character(df.clean$BIOTYPE)))

str(df.clean[,c("SIFT", "PolyPhen","BLOSUM62","Feature_type", "BIOTYPE")])
```

### EDA: Remaining NA

Remaining NA values will be identified for imputation. It should be noted that several
columns have essentially NA values. CLNDN has several entries that equate to NA,
but as the very absence of this information may be significant they will be collapsed
into one class for further feature engineering downstream.

EXON, cDNA_position, CDS_position, Protein_position, Amino_acids, an Codons all 
have empty strings in similar quantities indicating a pattern, and confirmed by
the fact that they are all associated with non-coding assignments in the Consequence
column. This is highlighted in the table below.

```{r EDA.Intron.values, echo = FALSE}
# get positional columns
positional.cols <- c("EXON", "cDNA_position", "CDS_position","Protein_position",
                     "Amino_acids","Codons")

# add check columns
check.cols <- c("CLASS", "Consequence", positional.cols)

intron.check <- df.clean[rowSums(df.clean[, positional.cols] == "") > 0, 
                 c(check.cols)]

knitr::kable(head(intron.check))
```

The empty values for the positional columns will be replaced with a non_coding
indicator to preserve biological context.

```{r EDA.NA.assign, echo = FALSE}

# Assign not_specified in CLNDN
df.clean$CLNDN <- ifelse(df.clean$CLNDN %in% c("not_specified", "not_provided",
                                               "not_specified|not_provided",
                                               "not_provided|not_specified" ),
                                               "not_specified",
                                               df.clean$CLNDN)

# Assign "non_coding" for positional data
positional.cols <- c("EXON", "cDNA_position", "CDS_position","Protein_position",
                     "Amino_acids","Codons")

# Use mutate to preserve levels (replaces with index otherwise)
df.clean <- df.clean %>%
  mutate(across(all_of(positional.cols),
                ~ factor(ifelse(. == "", "non_coding", as.character(.)))))


intron.recheck <- df.clean[rowSums(df.clean[, positional.cols] == "non_coding") > 0, 
                 c(check.cols)]

knitr::kable(head(intron.recheck))
```

All NA values have been handled at this point with the exception of true NA values
within otherwise informative columns.

```{r EDA.NA.stragglers, echo = FALSE}
colSums(is.na(df.clean))
```

LoFtool, CADD_PHRED, and CADD_RAW NA values will be imputed using kNN
regression. kNN was chosen over a linear model to avoid bias and assumptions
regarding distribution of data. [Documentation]("https://recipes.tidymodels.org/reference/step_impute_knn.html")
for the method used is available here.

STRAND has only a small amount of NA values, they will simply be dropped.

```{r EDA.NA.impute, echo = FALSE}

# get cols to impute
cols.to.impute <- c("LoFtool", "CADD_PHRED", "CADD_RAW")

k <- 5 # empirical square root method gave poor results

# start recipe
knn.recipe <- recipe(CLASS ~ ., data = df.clean) %>%
  step_impute_knn(
    all_of(cols.to.impute),
    impute_with = imp_vars(all_predictors()),  # let the model decide what matters
    neighbors = k
    )

# get imputed columns
knn.prep <- prep(knn.recipe, training = df.clean)
df.knn <- bake(knn.prep, new_data = NULL)
df.knn <- df.knn[,cols.to.impute] # save space

#subset into new dataframe
df.imputed <- df.clean
df.imputed[,cols.to.impute] <- df.knn[,cols.to.impute]

# remove STRAND NA
df.imputed <- df.imputed[!is.na(df.imputed$STRAND), ]
```

A final check will be made to sensure NA values have been removed.

```{r EDA.NA.Check, echo = FALSE}
colSums(is.na(df.imputed))
```
No NA found.

### EDA: Handling Outliers

Outliers in continuous variables will be identified and removed, using a z.score
greater than 3.0  as the threshold.

```{r EDA.OUTLIER.ID, warning=FALSE, echo = FALSE}
cont.vars <- c("AF_ESP","AF_EXAC","AF_TGP","LoFtool","CADD_PHRED","CADD_RAW")

# identify outliers
df.outliers <- df.imputed %>%
           # use scale to find outliers
           mutate(across(all_of(cont.vars), scale, .names = "z.{col}")) %>%
           # get outliers
           filter(if_any(starts_with("z."), function(col) abs(col) > 3)) %>%
           select(CLASS, all_of(cont.vars), starts_with("z."))

head(df.outliers)
```

There are over `r nrow(df.outliers)` outliers. They will be imputed via kNN 
using the same process that was applied to NA values.

```{r EDA.IMPUTE.outliers, echo = FALSE}

# assign NA
df.imputed <- df.imputed %>%
 # replace outliers with NA
  mutate(across(all_of(cont.vars), function(x) ifelse(abs(scale(x)) > 3, NA, x))) %>%
  # retain correct datatype after imputation  (wierd column names otherwise)
  mutate(across(all_of(cont.vars), as.numeric))

# impute with kNN
knn.recipe <- recipe(CLASS ~ ., data = df.imputed) %>%
  step_impute_knn(
    all_of(cont.vars),
    impute_with = imp_vars(all_predictors()),  # let the model decide what matters
    neighbors = k
    )

# get imputed columns
knn.prep <- prep(knn.recipe, training = df.imputed)
df.knn <- bake(knn.prep, new_data = NULL)
df.knn <- df.knn[,cont.vars]

#subset into new dataframe
df.imputed[,cont.vars] <- df.knn[,cont.vars]
```

### EDA: MultiColinearity Assesment

Decision Trees, Random Forest, and to a certain extent logistic regression with 
elastic net can be resistant to multicolinearity naturally, to optimize the 
models and minimize variance it is still reasonable to identify any potential 
multicolinearity.

```{r EDA.Colin.Cont, echo = FALSE}
#identify colinearity in continuous variables
df.imputed$CLASS <- as.numeric(as.character(df.imputed$CLASS))

pairs.panels(df.imputed[, c(cont.vars, "CLASS")])
```

It appears that AF_ESP, AF_EXAC, and AF_TGP are all strongly correlated, this is
reasonable as they are all allele frequency metrics.

Several categorical variables appear to be closely related based on previous
analysis.

They include, CLNDISDB, and CLNDN, which are codes representing various diseases,
and a human readable version respectively.

SYMBOL and Feature, where feature contains a code for a transcription
factor for a particular gene are also closely related.

cDNA_position, CDS_position, and Protein_position are also highly correlated based
on biological context alone. 

For the decision tree and randomforest models these will be retained, as these models
are generally resistant to multicollinearity and in fact they performed *worse* when
removed during testing.

The logistic regression model with elastic net being implemented is arguably more
susceptible to multicollinearity, however downstream testing showed that the model
performed poorly when it was performed. This will be shown downstream
 
```{r EDA.COLIN.vector, echo = FALSE}
colin.vars <- c("AF_ESP", "AF_EXAC","CADD_RAW","CLNDISDB", "Feature",
                "cDNA_position", "Protein_position")
```
 


### EDA: Feature by Feature Investigation

A more in depth investigation of each feature will be conducted to better perform
feature engineering and encoding.

### EDA: Continous Features

AF_XXX features and CADD_XXX scores will be shown for one variable each, their 
distributions are extremely similar.

```{r EDA.contfeatures, warning=FALSE, echo = FALSE}
# ensure class is factor
df.imputed$CLASS <- as.factor(df.imputed$CLASS)

ggplot(df.imputed, aes(x = CLASS, y = AF_TGP, fill = CLASS)) +
  geom_boxplot(alpha = 0.7) +
  scale_y_log10()+
  labs(title = "Class Dist. by Allele Frequency",
       y = "Allele Frequency", x = "CLASS")
```

Distribution shows that allele frequency is notably lower, this is reasonable 
given that rarer alleles are typically harder to study. 

```{r EDA.cont.transformations, warning=FALSE, echo = FALSE}
# combine into one plot
par(mfrow = c(3, 3), mar = c(4, 4, 4, 4))
# AF_TGP
hist(df.imputed$AF_TGP, main = "AF_TGP")
hist(sqrt(df.imputed$AF_TGP), main = "SQRT AF_TGP")
hist(log(df.imputed$AF_TGP +1), main = "Log AF_TGP")

# CADD_Phred
hist(df.imputed$CADD_PHRED, main = "CADD_PHRED")
hist(sqrt(df.imputed$CADD_PHRED), main = "Sqrt CADD_PHRED")
hist(log(df.imputed$CADD_PHRED), main = "Log CADD_PHRED")

# CADD_RAW
hist(df.imputed$CADD_RAW, main = "CADD_RAW")
hist(sqrt(df.imputed$CADD_RAW), main = "Sqrt CADD_RAW")
hist(log(df.imputed$CADD_RAW +1), main = "Log CADD_RAW")
```

It should be noted that while transformation of AF_TGP showed a marginaly better 
distribution, this transformation did not translate into an improvement in model
performance and was not retained. This sentiment was similar for all continuous
features.

Finally, transforms of CADD scores do show some potential but yielded poor results.
this will be shown downstream.

```{r EDA.CADD.vis, echo = FALSE}
ggplot(df.imputed, aes(x = CLASS, y = CADD_RAW, fill = CLASS)) +
  geom_boxplot(alpha = 0.7) +
  theme_bw() +
  labs(title = "CADD scores by CLASS", y = "CADD Score", x = "CLASS")
```

CADD scores show similar distribution across CLASS, though conflicting variants
may have slightly lower scores.

### EDA:"Low" cardinality Features

```{r EDA.Feature_Type, echo = FALSE}
df.counts.ft <- df.imputed %>%
  count(Feature_type)

ft.plot <- ggplot(df.imputed, aes(x=Feature_type, fill = CLASS)) +
  geom_bar(position = "fill") +
  geom_text(data = df.counts.ft,
            aes(x = Feature_type, y = 1.05, label = n), inherit.aes = FALSE)+
  theme_bw()

df.counts.bt <- df.imputed %>%
  count(BIOTYPE)

bt.plot <- ggplot(df.imputed, aes(x = BIOTYPE, fill = CLASS)) +
  geom_bar(position = "fill") +
  geom_text(data = df.counts.bt,
            aes(x = BIOTYPE, y = 1.05, label = n), inherit.aes = FALSE)+
  theme_bw()

grid.arrange(ft.plot, bt.plot,
             widths=c(2,2)) 
```

When NA in STRAND were dropped it removed the "missing" categories. Feature_type
is dominated by the Transcript class. Biotype shares a similar distribution
as Feature_type. In both cases the columns are heavily dominated by one class and
offer no real signal. They will be removed downstream.

```{r EDA.ORIGIN, echo = FALSE}
ggplot(df, aes(x=ORIGIN, fill = CLASS)) +
  geom_bar(position = "fill") +
  theme_bw() +
  labs(title = "Distribution of CLASS by ORIGIN")
```

ORIGIN indicates the source of the variant using bit notation. The table below shows
there are several entries that have only a few data points. This can be converted
to a binary column indicating if it is classified as 1 or something else.

```{r EDA.ORIGIN.TABLE, echo = FALSE}
table(df.imputed$ORIGIN)
```
The table above shows counts for individual ORIGIN scores, supporting conversion
to a dummy coded feature.

```{r EDA.IMPACT, echo = FALSE}
ggplot(df, aes(x=IMPACT, fill = CLASS)) +
  geom_bar(position = "fill") +
  theme_bw() +
  labs(title = "Distribution of CLASS by IMAPCT")
```

It appears that if a variant is High impact, there is less likely to be contention
about a variant's classification. In this case a simply dummy encoding a "HIGH" 
indicator will be sufficient.

CHROM and CLNV are compared below.

```{r EDA.CHROM.VIS, echo = FALSE}
chm.plot <- ggplot(df.imputed, aes(x=CHROM, fill = CLASS)) +
  geom_bar(position = "fill") +
  coord_flip()+
  theme_bw()

cln.plot <- ggplot(df.imputed, aes(x=CLNVC, fill = CLASS)) +
  geom_bar(position = "fill") +
  coord_flip() +
  theme_bw()

grid.arrange(chm.plot, cln.plot,
             widths=c(2,2)) 
```

There is some variation in CLASS distribution across each Chromosome with a notable
increase in uncertainty in mitochondrial DNA, of course there are only a few
observations as seen in the table below. Weight of Evidence (WOE) encoding will
be applied here due to cardnality.

```{r EDA.CHROM.table, echo = FALSE}
table(df.imputed$CHROM)
```

CLNVC shares a similarities to  CHROM, with Microsatellite variants being more 
likely to have contention. WOE will be applied here as well.

SIFT, PolyPhen, and BLOSUM62 contain large amounts of missing values, however they also
contain information regarding a variant's pathogenicity and deviation from the original
sequence. A more in depth look is warranted.

```{r EDA.SIFT.VIS, warning = FALSE, echo = FALSE}
ggplot(df.imputed, aes(x=SIFT, fill = CLASS)) +
  geom_bar(position = "fill")+ 
  labs(title = "Distribution of CLASS in SIFT",
       y = "Proportion", fill = "CLASS")+
  theme_bw()
```

There is very little variation in the distribution of CLASS across categories, while
is likely not individually predictive, theres a strong possibility it has signal
when combined with other features. This feature will undergo WOE encoding 
with the high-cardinality variables.  

```{r EDA.PolyPhen.VIS, echo = FALSE}
ggplot(df.imputed, aes(x=PolyPhen, fill = CLASS)) +
  geom_bar(position = "fill") +
  labs(title = "Distribution of CLASS in PolyPhen",
       y = "Proportion", fill = "CLASS")+
  theme_bw()
```

PolyPhen has slight variation around  each category, while there are only 4
entries for the unknown category, half are positive for conflicted status. WOE 
encoding will be applied.

```{r EDA.CLASS.DIST.BLOSUM62, echo = FALSE}
# Display Class distribnution of BLOSUM scores
ggplot(df.imputed, aes(x=BLOSUM62, fill = CLASS)) +
  geom_bar(position = "fill") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.05)) +
  labs(title = "Distribution of CLASS in BLOSUM62",
       x= "Modified Score", y = "Proportion", fill = "CLASS")+
  theme_bw()
```

From the chart and table we can see that there is some deviation of our positive class
distribution. 3 and -3 BLOSUM62 scores (6 and 1) especially show a difference. 
WOE encoding will be applied.

### EDA: High Cardinality Features.

Recall from the summary call that the REF and ALT features. In their current state
they do not provide data useful to a machine learning mode, but they do contain
quite a bit of useful information.

```{r EDA.REF.ALT, echo = FALSE}
gene_ct <- df %>%
  count(REF, CLASS) %>%
  pivot_wider(names_from = CLASS, values_from = n, values_fill = 0) %>%
  mutate(All = rowSums(across(where(is.numeric)))) %>%
  arrange(desc(All))

top_50_genes <- gene_ct %>%
  slice_head(n = 30) %>%
  pull(REF)

gene_ct_long <- gene_ct %>%
  select(-All) %>%  # keep only CLASS columns
  pivot_longer(cols = -REF, names_to = "CLASS", values_to = "count")

gene_ct_long_top <- gene_ct_long %>%
  filter(REF %in% top_50_genes)

ggplot(gene_ct_long_top, aes(x = reorder(REF, -count), y = count, fill = CLASS)) +
  geom_col() +
  labs(title = "Distribution of CLASS for Top 50 REF",
       x = "Reference Sequence", y = "Count", fill = "CLASS") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

From these features we can discern a few things. Whether the variant
is a Single nucleotide variant, insertion, deletion, the change in length of
the variant, and whether or not the SNVs were transitions or transversions. 

Based on an analysis performed [here](https://www.kaggle.com/code/vasilyb/clinvar-identifying-conflicting-genetic-variants#2.-DATA-TRANSFORMATION)
and some experimentation not shown. A binary SNV column will be added, and the 
lengths of reference,alt,and allele, be added as columns.


```{r EDA.Consequence, echo = FALSE}
ggplot(df, aes(x=Consequence, fill = CLASS)) +
  geom_bar(position = "fill") +
  coord_flip() +
  labs(title = "Distribution of CLASS in Consequence",
       y = "Proportion", fill = "CLASS")+
  theme_bw()
```

Consequence and MC have several levels with low frequency that are unique combinations
of individual levels and the same name, in this case one-hot encoding the data with binary columns
for individual levels will decrease the overall complexity of the data and make it
more interpretable to ML models by allowing them to capture obervations consistently
marked with several variables.

The Chart below shows a distribution of the positive CLASS by gene SYMBOL, it is an
adaptation of one found [here](https://www.kaggle.com/code/kevinarvai/genetic-variant-classifications-eda)
and was implemented to highlight the importance of one of the high cardinality features.

It should be noted that there are other features such as CLDN that share this 
cardinality problem and will require a robust method to accurately capture the
relationship they have with the the target variable.

```{r EDA.CLASS.dist.by.SYMBOL, echo = FALSE}
gene_ct <- df %>%
  count(SYMBOL, CLASS) %>%
  pivot_wider(names_from = CLASS, values_from = n, values_fill = 0) %>%
  mutate(All = rowSums(across(where(is.numeric)))) %>%
  arrange(desc(All))

top_50_genes <- gene_ct %>%
  slice_head(n = 50) %>%
  pull(SYMBOL)

gene_ct_long <- gene_ct %>%
  select(-All) %>%  # keep only CLASS columns
  pivot_longer(cols = -SYMBOL, names_to = "CLASS", values_to = "count")

gene_ct_long_top <- gene_ct_long %>%
  filter(SYMBOL %in% top_50_genes)

ggplot(gene_ct_long_top, aes(x = reorder(SYMBOL, -count), y = count, fill = CLASS)) +
  geom_col() +
  labs(title = "Distribution of CLASS for Top 50 Genes",
       x = "Gene Symbol", y = "Count", fill = "CLASS") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

From the chart above certain well studied genes have a large number of variants
with conflicting status. Two examples TITN and BRCA1 are excellent representations
of the problem. TITN due to it's size  and complexity is difficult to characterize,
and BRCA1 is associated with breast cancer, which is a complex disease that can have 
dependence on multiple factors impacting a variants pathogenic status.

## Encoding and Engineering Features

Features will be encoded and engineered based on discussion during EDA, starting
with low cardinality features then progressing to high cardinality.

### Encoding Low Cardinality Data

First, dummy encoding of features.

```{r ENCODE.binary.func}
binary.func <- function(df) {
  # encode based on EDA
  df$ORIGIN <- ifelse(df$ORIGIN == 1, 0, 1)
  df$IMPACT <- ifelse(df$IMPACT == "HIGH", 1, 0)
  df$POS_STRAND <- ifelse(df$STRAND == 1, 1, 0)
  
  return(df)
}
```

A function was written to encode Origin, Impact and Strand for any given dataframe.

```{r ENCODE.DUMMY, echo = FALSE}

df.imputed <- binary.func(df.imputed)

str(df.imputed[, c("ORIGIN", "IMPACT", "POS_STRAND")])
```

The features are now encoded and ready for modeling.

```{r ENCODE.SNV.func, echo = FALSE}
SNV.func <- function(df){
  #add columns with length of reference and vairants
  df.new <- df %>%
  mutate(REF_length = nchar(as.character(REF)),
         ALT_length = nchar(as.character(ALT)),
         Allele_length = nchar(as.character(Allele)))

  # use length columns to create SNV column
  df.new <- df.new %>%
    mutate(SNV = ifelse(REF_length == 1 & ALT_length == 1, 1, 0))
  
  # remove columns
  df.new <- df.new %>% select(-REF,-ALT,-Allele)
  
  return(df.new)
}
```

A function to create new features with the lengths of nucleotides and generate a 
feature indicating if a variant is single nucleotide in nature or not.

```{r ENCODE.SNV, echo = FALSE}
# apply to dataframe
df.imputed <- SNV.func(df.imputed)


# quick check
str(df.imputed[, c("REF_length", "ALT_length", "Allele_length", "SNV")])
```
The table shows the new length features and the SNV feature.

The features are now engineered, encoded and ready for modeling.

### Encoding High Cardinality Data

Consequence and MC have mostly matching names once the character strings are split.
A function was written to handle the heavy lifting.

```{r ENCODE.split.cons.mc.func, echo = FALSE}

split.variants <- function(df) {
  # Add row.id for later joing
  df <- df %>% mutate(row.id = row_number())

  # start with MC splitting on "," and removing SO:000xx code from data
  df.mc <- df %>%
    separate_rows(MC, sep = ",") %>%
    mutate(MC = str_remove(MC, "SO:\\d+\\|")) %>%
    mutate(value = 1) %>%
    distinct(row.id, MC, .keep_all = TRUE) %>%
    pivot_wider(id_cols = row.id, names_from = MC, values_from = value,
                values_fill = 0)

  # Group rare terms into "other" column
  mc.counts <- colSums(df.mc %>% select(-row.id))
  rare.mc <- names(mc.counts[mc.counts <= 26]) # 26 handles an edge case
  # create binary col for other cases
  df.mc$MC.OTHER <- as.integer(rowSums(df.mc[, rare.mc, drop = FALSE]) > 0)

  # repeat with consequence separating on &
  df.cons <- df %>%
    separate_rows(Consequence, sep = "&") %>%
    mutate(value = 1) %>%
    distinct(row.id, Consequence, .keep_all = TRUE) %>%
    pivot_wider(id_cols = row.id, names_from = Consequence, values_from = value,
                values_fill = 0)

  # Group rare terms into "other" column
  cons.counts <- colSums(df.cons %>% select(-row.id))
  rare.cons <- names(cons.counts[cons.counts <= 26]) # 26 handles an edge case
  # create binary col for other cases
  df.cons$Cons.OTHER <- as.integer(rowSums(df.cons[, rare.cons, drop = FALSE]) > 0)

  # combine data
  df.mcons <- full_join(df.mc, df.cons, by = "row.id")

  shared.cols <- setdiff(intersect(names(df.mc), names(df.cons)), "row.id")
  for (col in shared.cols) {
  df.mcons[[col]] <- ifelse(
    df.mcons[[paste0(col, ".x")]] + df.mcons[[paste0(col, ".y")]] > 0, 1, 0)
  # remove duplicate columns
    df.mcons[[paste0(col, ".x")]] <- NULL
    df.mcons[[paste0(col, ".y")]] <- NULL
  }
  
  # Drop the original MC and Consequence cols
  df <- df %>% select(-MC, -Consequence)

  # Merge data back to original df
  df.final <- left_join(df, df.mcons, by = "row.id")

  # Fix column names that start with a number (R gets upset)
  names(df.final) <- make.names(names(df.final), unique = TRUE)
  return(df.final)
  }
```

Now comes the implementation, several comes will be combined based on biological
context to reduce noise, or because they have only a few positive classes. For 
example upstream variants and 500 byte upstream variants were combined to
reduce dimensionality and noise.

```{r ENCODE.split.cons.MC, echo = FALSE}

# Run the function
df.sep <- split.variants(df.imputed)

# combine columns based on biological context to reduce noise
df.sep$upstream_gene_variant <- ifelse(df.sep$upstream_gene_variant == 1 
                                       | df.sep$X2KB_upstream_variant == 1, 1, 0)

df.sep$downstream_gene_variant <- ifelse(df.sep$downstream_gene_variant == 1 
                                       | df.sep$X500B_downstream_variant == 1, 1, 0)

df.sep$splice_region_variant <- ifelse(df.sep$splice_region_variant == 1 
                                       | df.sep$splice_donor_variant  == 1, 1, 0)

df.sep$splice_region_variant <- ifelse(df.sep$splice_region_variant == 1 
                                       | df.sep$splice_acceptor_variant  == 1, 1, 0)

# remove  unused columns
df.sep <- df.sep %>% select(-X2KB_upstream_variant, -X500B_downstream_variant,
                            -splice_donor_variant, -splice_acceptor_variant,
                            -stop_retained_variant, -start_retained_variant)

# remove sparse or otherwise unused variables such as STRAND
df.sep <- df.sep %>% select(-nan, -TF_binding_site_variant, -STRAND, -MC.OTHER,
                            -BIOTYPE, -stop_lost, -coding_sequence_variant,
                            -protein_altering_variant, -Feature_type, -row.id,
                            -non_coding_transcript_variant)
#check new variables
str(df.sep[,29:ncol(df.sep)])
```

The data from MC and Consequence is now expanded into ML readable format and
optimized.

Two steps were taken to encode the remaining High-cardinality data, first low-frequency
categories were be binned into a "low.freq" group to reduce noise, then those 
updated features were encoded using weight of evidence.


```{r ENCODE.bin.high.card, echo = FALSE}
high.card.features <- c("CLNDN", "SYMBOL","EXON","cDNA_position",
                        "Amino_acids","Codons", "CLNDISDB","Feature",
                        "CDS_position", "Protein_position")

min.count <- 200

for (feat in high.card.features) {
  # get frequencies
  freq <- table(df.sep[[feat]]) # remember [[]] returns a vector!
  
  # get low frequency levels
  low.freq <- names(freq[freq < min.count])
  
  # assign low freq
  df.sep[[feat]] <- ifelse(as.character(df.sep[[feat]]) %in% low.freq, 
                           "low.freq", 
                           as.character(df.sep[[feat]]))
  
  # remove old levels
  df.sep[[feat]] <- factor(df.sep[[feat]])
}

str(df.sep[,high.card.features])
```
Note the greatly reduced number of factor levels post binning.

The final step in the encoding process is weight of evidence encoding, this was
performed after the data is split into validation and training sets to prevent
data leakage. A function to handle the process was prepared here. Note that
a very small laplace smoothing factor was introduced due to sparsity of
some categories, even after binning.

```{r EDA.woe.func, echo = FALSE}
woe.func <- function(col, df) {
  
  # add laplace
  laplace = 0.000001 # value borrowed from tidyverse version
  
  # get counts
  counts <- table(df[,col])
  
  #identify positive counts
  pos <- tapply(df$CLASS == 1, df[,col], sum) # tapply for groups
  
  #identify negative counts
  neg <- counts-pos
  
  # calculate probabilities
  prob.pos <- (pos +laplace)/(sum(pos) +laplace*length(pos))
  
  prob.neg <- (neg +laplace)/(sum(neg) +laplace*length(neg))
  
  # calculate woe using formula
  woe <- log(prob.pos/prob.neg)
  
  return(woe)
}
```

## Prepare Data for modeling:

The data is ready for splitting into holdout validation and training sets, then
Weight of evidence encoding will be applied and feature selection will be performed
based on Chi-Square and XXXXX analysis


### Prepare: Split Data

First a standard 80/20 holdout split will be performed.

```{r PREPARE.split.data}
set.seed(42) # Answer to Universe life and everything in between

# get index
trnindx <- createDataPartition(df.sep$CLASS, p = 0.8, list = FALSE)

df.train <- df.sep[trnindx,]

# test
df.test <- df.sep[-trnindx,]
```


### Prepare: Woe Encoding

Features will be weight of evidence encoded, the table below shows the results
of the transformation.

```{r PREPARE.WOEencode, echo = FALSE}
high.card.features <- c("CLNDN","SYMBOL","EXON", "CHROM","cDNA_position","Amino_acids",
                        "Codons","PolyPhen", "BLOSUM62","CLNVC","SIFT",
                        "CLNDISDB","Feature", "CDS_position", "Protein_position")

#get weight of evidence for each column and save to list
woe.calcs <- lapply(high.card.features, function(col) woe.func(col, df.train))

# match names
names(woe.calcs) <- high.card.features

df.woe <-df.train
df.test3 <- df.test

#update categories with probabilities (use [[x]] to access list)
df.woe[high.card.features] <- lapply(high.card.features, function(col) {
                    as.numeric(woe.calcs[[col]][as.character(df.train[[col]])])})


df.test3[high.card.features] <- lapply(high.card.features, function(col) {
                    as.numeric(woe.calcs[[col]][as.character(df.test3[[col]])])})

# Matrix for Xgboost and logreg models
test.matrix <- as.matrix(df.test3[, !names(df.test3) %in% "CLASS"])


# check to ensure encoding
knitr::kable(head(round(df.woe[high.card.features],3)))
```


Features have now been encoded with WOE encoding, final step is correcting class
imbalance.

### Prepare: Correct Class Imbalance

Due to the class imbalance discovered during EDA, the training data will undergo
a resampling method combining upsampling and downsampling discussed [here](https://machinelearningmastery.com/combine-oversampling-and-undersampling-for-imbalanced-classification/)

```{r prepare.updown.sample, echo = FALSE}

df.up <- upSample(x = df.woe[, -which(names(df.woe) == "CLASS")],
                             y = as.factor(df.woe$CLASS),
                             yname = "CLASS")

df.down <- downSample(x = df.up[, -which(names(df.up) == "CLASS")],
                             y = as.factor(df.up$CLASS),
                             yname = "CLASS")

# Matrix for XGboost and glmnet models
xgb.matrix <- as.matrix(df.down[, !names(df.down) %in% "CLASS"])
xgb.label <- as.integer(as.character(df.down$CLASS))


table(df.down$CLASS)
```

The class imbalance has now been addressed.

### Prepare: Log Regression Data

For comparison a set of data was prepared for the logreg model that controls
for collinearity, transforms relevant data to a normal distribution and scales.
This step was wrapped in a function to simplify the process.

```{r Prepare.logreg.wrapper}
normalize.it<- function(df){
  # remove colinear variables from EDA
  df.colin <- df[, !names(df) %in% colin.vars]
  
  # apply square root transform on CADD_PHREDD
  df.colin$CADD_PHRED <- sqrt(df.colin$CADD_PHRED)
  
  # vector of features to scale
  to.scale <- c("AF_TGP", "CDS_position", "CADD_PHRED", "REF_length", "ALT_length"
                , "Allele_length")
  #standardize features using scale
  scaled.feat <- scale(df.colin[, names(df.colin) %in% to.scale])
  
  # assing to dataframe
  df.scale <- df.colin
  df.scale[,to.scale] <- scaled.feat
  
  df.scale$CLASS <- as.numeric(as.character(df.scale$CLASS))
  
  return(df.scale)
}
```


### Prepare: Feature Selection

Chi-Square, ANOVA, and PCA will be conducted. Chi-Square for all encoded features,
ANOVA analysis for all continuous features, PCA will be used to get an idea of
how the WOE encoded features are playing a role.

PCA will be performed to get an idea of the constituent components.

Final features for modeling will be selected based on p-value threshold.

#### Prepare: Chi Square Analysis

```{r prepare.chisq, echo = FALSE}
# get features
bi.vars <- df.down %>%
  select(where(~ all(. %in% c(0, 1))))


# perform chi square
chisq.results <- lapply(names(bi.vars), function(var) {
  table <- table(bi.vars[[var]], df.down$CLASS)
  test <- chisq.test(table)
  list(variable = var,
       pvalue = test$p.value,
       statistic = test$statistic,
       expected = test$expected)
})

# get results as dataframe
chisq.df <- do.call(rbind, lapply(chisq.results, function(res) {
  data.frame(Feature = res$variable,
             pvalue = res$pvalue,
             chisq.stat = res$statistic)
}))

# Sort by pvalue
chisq.summary <- chisq.df[order(chisq.df$pvalue), ]

# display Features with no correlation
bad.features <- chisq.summary$variable[chisq.summary$pvalue > 0.05]

to.remove <- length(bad.features)

head(chisq.summary)
```

From the table it can be seen that several of the engineered features hold
predictive value based on P values and Chi Square statistic.

There are `r to.remove` features that are not significant. Chi Square analysis 
suggests all catregorical features are statistically significant.

#### Prepare: ANOVA Analysis

ANOVA testing of the continuous variables was performed, the table below shows
that all of the featurees are significant.

```{r prepare.ANOVA, echo = FALSE}

# get continuous variables
cont.vars <- c("AF_ESP","AF_EXAC","AF_TGP","LoFtool","CADD_PHRED","CADD_RAW")

df.cont <- df.down[, c(cont.vars, "CLASS")]

# get ANOVA
anova.results <- lapply(cont.vars, function(var) {
  
  formula <- as.formula(paste(var, "~ CLASS"))
  
  aov_result <- summary(aov(formula, data = df.cont))
  pval <- aov_result[[1]]["CLASS", "Pr(>F)"]

  data.frame(Feature = var,
             pvalue  = pval)
})

# combine and list
anova.summary <- do.call(rbind, anova.results)
anova.summary <- anova.summary[order(anova.summary$pvalue), ]
anova.summary
```

All six continuous variables are strongly significant based on pvalue.

#### Prepare: Principle Component Analysis

PCA was performed to identify features responsible for variance within the datset.
Some of the techniques found [here](https://www.r-bloggers.com/2021/05/principal-component-analysis-pca-in-r/)
were incorporated into the analysis.

```{r prepare.PCA, echo = FALSE}
# exclude target feature
df.features <- df.down[, !(names(df.down) %in% "CLASS")]

# use pr comp to eval
`PCA Results` <- prcomp(df.features, center = TRUE, scale. = TRUE)

# get elbow plot
plot(`PCA Results`, type = "l")
```

From the elbow plot we see that most variance can be explained by the first 8 or
9 principle components. The table below shows some of the features contributing
to the first five principle components.

```{r prepare.PCA.closerlook, echo=FALSE}
head(round(`PCA Results`$rotation[, 1:5],3),20)
```

It appears that the WOE encoded variables do meaningfully represent the variance of the
dataset based on the weights for various positions in PC1 and Clinical diagnoses in
PC3. 


## BUILD: MODELS

Three models will be created, a boosted decision tree, a random forest model, and
a logistic regression with an elastic net. 

the tree based models are highly resistant to noisy data found in this dataset and
well suited to capturing nonlinear patterns, the enhanced logistic reggression model
provides interpetibility, and will balance the tree models tendency to over fit the data
with the regularization provided by the elastic net.

### BUILD: Base models

Base models were constructed one boosted tree, a random forest, and a logistic
regression model with elastic net. 

```{r BUILD.models, message = FALSE}
# Tree
model.x <- xgboost(data=xgb.matrix, label = xgb.label, nrounds=100,
                   objective = "binary:logistic", verbose = 0) # silence printout

# random forest
model3.s  <- ranger(CLASS ~ ., data = df.down, probability = TRUE)

# logreg model
model.g <- glmnet(xgb.matrix, y=xgb.label, family = binomial, standardize = TRUE)

#normalized logreg model
model.n <- glmnet(as.matrix(normalize.it(df.down)), y=xgb.label,
                  family = binomial, standardize = FALSE)
```

### BUILD: Base Model Predictions

The boosted decision tree and random forest model predictions are shown below.

```{r BUILD.basetree.preds, echo = FALSE}
# Decision Tree
treepreds.x <- predict(model.x, test.matrix)
treepreds.x <- ifelse(treepreds.x > 0.5, "1", "0")
treepreds.x <- factor(treepreds.x, levels = c("0", "1"))

confusionMatrix(treepreds.x, df.test3$CLASS, positive = "1")
```

The boosted tree shows reasonable sensitivity and specificity, with some concern
for its weak positive predictive value or precision. 

The random forest model output is hown below.

```{r BUILD.baseforest.preds, echo = FALSE}
# randomforest preds
forestpreds <- predict(model3.s, df.test3)
forest.probs <- forestpreds$predictions[, "1"]
forest.class <- ifelse(forest.probs >= 0.5, "1", "0")
forest.class <- factor(forest.class, levels = c("0", "1"))
confusionMatrix(forest.class, df.test$CLASS, positive = "1")
```

The random forest model performs similarly to the boosted decision tree. Notably,
it's precision is higher and has a higher sensitivity.

Now a comparison of the logistic regression models with and without handling
of collinearity.

```{r BUILD.logregpreds, echo = FALSE}
# Logistic regression preds
logreg.preds <- predict(model.g, test.matrix, s = 0.01, type = "response")
logreg.preds <- ifelse(logreg.preds > 0.5, "1", "0")
logreg.preds <- factor(logreg.preds, levels = c("0", "1"))

confusionMatrix(logreg.preds, df.test3$CLASS, positive = "1")


# normalized logreg preds
logreg.preds.n <- predict(model.n, as.matrix(normalize.it(df.test3))
                          ,s = 0.01, type = "response")
logreg.preds.n <- ifelse(logreg.preds.n > 0.5, "1", "0")
logreg.preds.n <- factor(logreg.preds.n, levels = c("0", "1"))

confusionMatrix(logreg.preds.n, df.test3$CLASS, positive = "1")

```

The tree and forest models have similar accuracy scores, interestingly the Tree
model is more sensitive while the ranger model has high specificity. Indicating 
they complement each other well.

The logistic regression model underperformed in terms of *overall* accuracy 
compared to the tree based models, but had the highest sensitivity of all of them
and its balanced accuracy was not unreasonably far behind.This was at the cost of
a large number of false positives.Note the poor performance of the logreg model 
with transformations, normalization and collinear features removed. likely the 
signal each feature was contributing was weak on it's own and removal made the 
signal imperceptible. 

F1 scores will be calculated to determine each models efficacy at identifying 
conflicting variants.

### BUILD: F1 score for Base Models

An F1 function was defined and the F1 scores calculated for each model.

```{r BUILD.base.f1.func, echo=FALSE}
f1 <- function(preds, test) {
    #ensure preds and test are factors
    preds  <- factor(preds,  levels = c("0", "1"))
    test <- factor(test, levels = c("0", "1"))
    
    # get precision and recall (caret:: or functioon is masked) 
    prec <- caret::posPredValue(preds, test, positive = "1")
    recall <- caret::sensitivity(preds, test, positive = "1")
    
    F1 <- 2 * (prec * recall) / (prec + recall)
    
    return(F1)
}
```


```{r BUILD.Get.F1, echo=FALSE}
tree.f1 <- f1(treepreds.x, df.test3$CLASS)
forest.f1 <- f1(forest.class, df.test3$CLASS)
logreg.f1 <- f1(logreg.preds, df.test3$CLASS)

F1.Base <-rbind( Tree = tree.f1,
                 Forest = forest.f1,
                 Log.Reg = logreg.f1)

knitr::kable(F1.Base)
```

The Tree model has the highest F1 score, and the log regression has the lowest.
From a general standpoint they are on the low side, however inth e context of the 
dataset they are respectable.

### BUILD: ROC Base models

ROC curve for each of the models was calculated with optimal specificity and 
sensitivity thresholds determined. 

```{r BUILD.ROCbase, message=FALSE, echo = FALSE}
# tree
treeprobs.x <- predict(model.x, test.matrix)
roc.xgb<- roc(df.test3$CLASS, treeprobs.x)
tree.thresh <-coords(roc.xgb, "best", transpose = FALSE)
# forest
forestpreds <- predict(model3.s, df.test3, type = "response")
forest.probs <- forestpreds$predictions[, "1"]

roc.forest <- roc(df.test3$CLASS, forest.probs)
forest.thresh <- coords(roc.forest, "best", transpose = FALSE)
# logreg
logreg.probs <- predict(model.g, test.matrix, s = 0.01, type = "response")[, 1]
roc.logreg <- roc(df.test3$CLASS, logreg.probs, levels = c("0", "1"), direction = "<")
logreg.thresh <-coords(roc.logreg, "best", transpose = FALSE)

# store best thresholds
best.thresholds <- bind_rows(tree.thresh, forest.thresh, logreg.thresh)
best.thresholds
```

Interestingly the default choice of 0.5 for a threshold was fairly close for
the decision tree and log reg model. The Random forest required a much lower 
value to optimize sensitivity and specificity. 

```{r BUILD.ROC.display, echo = FALSE}
plot(roc.xgb, col = "red", legacy.axes = TRUE)
plot(roc.forest, col="green", add= TRUE)
plot(roc.logreg, col = "blue", add = TRUE)
title(main = "Comparison of Base model ROC's", line = 2.5)
```


The tree and forest models are comparable, with the tree model edging out the forest 
model slightly. The logistic regression model has the poorest curve and lowest F1 
score by far.

These values are poor due to the noise of the dataset. When  placed in the context
of other modeling attempts on this dataset they are on the higher end.

Further improvements will be made by constructing a stacked ensemble model.

## Evaluation and Tuning

The data is split again for future training of the stacked model, and K fold 
validation and bagging is set up. 

### EVAL: Holdout data for training

A second split of data was performed to prevent data leakage when training
the stacked model. This was again done as an 80/20 split.

```{r EVAL.Stack.Holdout}
# ensure reproducibility
set.seed(42)

meta.trn <-createDataPartition(df.woe$CLASS, p = 0.8, list = FALSE)

meta.train <- df.woe[meta.trn,]
meta.test <- df.woe[-meta.trn,]
```

```{r CARET.compliantfactors, echo = FALSE}
# relabel CLASS to comply with R naming and Caret function conventions
meta.train$CLASS <- factor(meta.train$CLASS, levels = c(0, 1), labels = c("X0", "X1"))
meta.test$CLASS <- factor(meta.test$CLASS, levels = c(0, 1), labels = c("X0", "X1"))
df.test3$CLASS <- factor(df.test3$CLASS, levels = c(0, 1), labels = c("0", "1"))
```


### EVAL: Up Down Sampling for Bagged Models


To prevent data leakage our bagged models needs to be up and down 
sampled during the k-fold step. This was specified in Caret using a custom
function. An explanation of this technique is found [here](https://topepo.github.io/caret/subsampling-for-class-imbalances.html#using-custom-subsampling-techniques)

```{r EVAL.Sample.custom, echo = FALSE}
updown <- list(
  # name method
  name = "UpDown",
  # define sampling method (x,y format REQUIRED)
  func = function(x, y) {
    
    # Upsample first
    up <- upSample(x = x, y = y, yname = ".y")
    
    # Then downsample
    down <- downSample(
      x = up[, !names(up) %in% ".y"],
      y = up$.y,
      yname = ".y"
    )
    
    return(list(x = down[, !names(down) %in% ".y"], y = down$.y))
  },
  first = TRUE # refers to preprocessing kept from template
)
```


### EVAL: Bootstrapping bagged models

```{r EVAL.TRAINCONTROL}
# ensure reproducibility
set.seed(42)

# Use different random seeds for each trial 
seeds <- vector(mode = "list", length = 51)
for(i in 1:50) seeds[[i]] <- sample.int(1000, 50)

## For the last model:
seeds[[51]] <- sample.int(1000, 1)


# 5 fold cross validation best model predictions saved for training stacked model
trnctrl <- trainControl(method = "cv", number = 5, savePredictions = "final",
                        classProbs = TRUE, seeds = seeds, verboseIter = FALSE,
                        summaryFunction = prSummary, sampling = updown)
```

The above allows us to establish a random seed for each step of k-fold validation
and bagged dataset. Bagging was combined with downsampling within a function
to traine ach model. prSummary was chosen as the summary function to allow 
training of the model using F1 score.

```{r EVAL.Bag.func, echo = FALSE}
bag.it <- function(df) {
  # initial randomization
  randomize <- sample(1:nrow(df), replace = T)
  df.bag <- df[randomize,]
  
  return(df.bag)
  }
```


```{r EVAL.Bag.data, echo = FALSE}
# build tree dataframes using unique seeds
tree.bags = list()
for (i in 1:3) {
  # get random seed
  set.seed(seeds[[i]][1]) # each entry in seeds is a list of seeds
  
  # save dataframes in list
  tree.bags[[i]] <- bag.it(meta.train)
}
# name them
names(tree.bags) <-paste0("treebag_", 1:3)
  
# forests dataframes using unique seeds
forest.bags = list()
for (i in 1:3) {
  set.seed(seeds[[i]][2])
  
  forest.bags[[i]] <- bag.it(meta.train)
}
names(forest.bags) <-paste0("forestbag_", 1:3)

# logreg dataframes using unique seeds
logreg.bags = list()
for (i in 1:3) {
  set.seed(seeds[[i]][3])
  
  logreg.bags[[i]] <- bag.it(meta.train)
}
names(logreg.bags) <-paste0("logregbag_", 1:3)
```

The holdout data was bootstrapped into 9 distinct datasets for training of 
homogenous bagged ensemble learners.

### EVAL: Ensemble Base Learners

The bagged data was used to train three base learners for a homogeneous
ensemble. Three base learners per ensemble was chosen due to time and memory
constraints. A wide range of hyperparemeters were experimented with. Out of 
respect for the reader's time and memory contraints only a few are shown.

Hyperparameters explored for the tree and forest models included boosting 
rounds, max tree depth, features per split (mtry) and node size. 

For the logistic regression model a wide range of alpha and lambda parameters 
were explored. The best results were found with a relatively weak lambda and a 
smaller alpha value lending more weight to the Ridge regularization aspect of the
elastic net.

```{r EVAL.TREES, message=FALSE}


tree.models <- list()

# establish grid with variables to try (reduced in size for time)
xgb.grid <- expand.grid(
  nrounds = c(150,200), # boosting rounds limited to 200  c(100,200,300,500)      
  max_depth = c(2,3), # shallow depth trees prevent overfitting c(2,3,5,7,10)             
  eta = c(0.4), # default learning rate c(0.3,0.4,0.5)         
  gamma = 0, # default                                  
  colsample_bytree = c(0.8,1), # proportion of features used in a  tree               
  min_child_weight = c(1),  # default              
  subsample = c(0.75, 1)  # proportion of training data per tree                
)


for (i in seq_along(tree.bags)) {
# Decision Tree, boosted
tree.final <- train(
  CLASS ~.,
  data = tree.bags[[i]],
  method = "xgbTree",
  trControl = trnctrl,
  tuneGrid = xgb.grid,
  metric = "F",
  verbosity = 0
)
tree.models[[i]] <- tree.final
}
names(tree.models) <-paste0("tree.model_", 1:3)
```


```{r EVAL.TREE.PREDS, echo = FALSE}

for (i in seq_along(tree.models)) {
  preds.tree <- predict(tree.models[[i]], meta.test, type = "prob")[, "X1"]
  preds.tree <- ifelse(preds.tree > 0.5, "X1", "X0")
  preds.tree <- factor(preds.tree, levels = c("X0", "X1"))
  print(caret::confusionMatrix(preds.tree, meta.test$CLASS, positive = "X1"))
}
```

All of the tree models share similar statistics, with some slight variation, 
notably they have strong sensitivity.

```{r EVAL.FOREST, message=FALSE}

forest.models <- list()

# establish grid with variables to try
rf.grid <- expand.grid(
  mtry = c(6), # minimum number of features per split c(4,5,6,7)
  splitrule = c("gini"), # gini impurity 
  min.node.size = c(3,5) # minimum observations per tree c(3,4,5,6)
)

# Random forest
for (i in seq_along(forest.bags)) {
forest.final <- train(
  CLASS ~.,
  data = forest.bags[[i]],
  method = "ranger",
  trControl = trnctrl,
  tuneGrid = rf.grid,
  metric = "F",
  verbose = FALSE
)
forest.models[[i]] <- forest.final
}
names(forest.models) <-paste0("forest.model_", 1:3)
```

```{r EVAL.FOREST.PREDS, echo = FALSE}
for (i in seq_along(forest.models)) {
  
  preds.forest <- predict(forest.models[[i]], meta.test, type = "prob")[, "X1"]
  preds.forest <- ifelse(preds.forest >= 0.5, "X1", "X0")
  preds.forest <- factor(preds.forest, levels = c("X0", "X1"))
  print(confusionMatrix(preds.forest, meta.test$CLASS, positive = "X1"))
}
```

The forest models share similar distributions, but their specificity is much 
higher than their sensitivity.

```{r EVAL.LOGREG}
logreg.models <- list()

# establish grid with variables to try
logreg.grid <- expand.grid(
  alpha = c(0.1, 0.2),  # controls blend of lasso and ridge       
  lambda = c(0.0002,0.00025, 0.0003)  # regularization strength
)

for (i in seq_along(logreg.bags)) {
# Decision Tree, boosted
logreg.final <- train(
  CLASS ~.,
  data = logreg.bags[[i]],
  method = "glmnet",
  trControl = trnctrl,
  tuneGrid = logreg.grid,
  metric = "F",
  verbose = FALSE
)
logreg.models[[i]] <- logreg.final
}
names(logreg.models) <-paste0("logreg.model_", 1:3)
```


```{r EVAL.LOGREGPREDS, echo = FALSE}
for (i in seq_along(logreg.models)){
  preds.logreg <- predict(logreg.models[[i]], meta.test, type = "prob")[, "X1"]
  preds.logreg <- ifelse(preds.logreg > 0.5, "X1", "X0")
  preds.logreg <- factor(preds.logreg, levels = c("X0", "X1"))
  print(confusionMatrix(preds.logreg, meta.test$CLASS, positive = "X1"))
}
```

The logistic regression model does not perform as well as the tree based models,
it strongly overestimates the positive class.

### EVAL: Ensemble Combine

Each set of the three models will be combined into a soft vote homogenous
ensemble learner wherein the mean of the three base leraners are averaged and
returned as the prediction. A generalized function was implemented for this 
purpose.

```{r EVAL.Ensemble.func}
Ensemble.model <- function(model.list, test.data) {

  # initialize list for preds with correct dims
  predictions <- data.frame(matrix(ncol = length(model.list),
                                   nrow=nrow(test.data)))
  # get predictions
  for (i in seq_along(model.list)) {
    # get initial predictions
    pred <- predict(model.list[[i]], test.data, type = "prob")[, "X1"]
    predictions[[i]] <- pred
  }
  # distinguish
  names(predictions) <- paste0("model_", seq_along(model.list))
  
 # Take the mean probability per row (i.e., across models)
  avg.preds <- rowMeans(predictions)

  
  # Final prediction based on averaged prob and threshold
  final.pred <- ifelse(avg.preds > 0.5, "X1", "X0")
  
  return(factor(final.pred, levels = c("X0", "X1")))
}
```

First the Tree ensemble will be examined.

```{r EVAL.Tree.Ensemble, echo = FALSE}
Tree.Ensemble <- Ensemble.model(tree.models, meta.test)

confusionMatrix(factor(Tree.Ensemble, levels = c("X0", "X1")),
                factor(meta.test$CLASS, levels = c("X0", "X1")),
                positive = "X1")
```

The homogeneous ensemble learner outperforms its base models, offering better
stats overall.

Now the random Forest model.

```{r EVAL.Forest.Ensemble, echo = FALSE}
Forest.Ensemble <- Ensemble.model(forest.models, meta.test)

confusionMatrix(factor(Forest.Ensemble, levels = c("X0", "X1")),
                factor(meta.test$CLASS, levels = c("X0", "X1")),
                positive = "X1")
```

A similar sentiment is shared by the homogenous forest model.

Finally the logistic regression model.

```{r EVAL.LogReg.Ensemble, echo = FALSE}
Logreg.Ensemble <- Ensemble.model(logreg.models, meta.test)

confusionMatrix(factor(Logreg.Ensemble, levels = c("X0", "X1")),
                factor(meta.test$CLASS, levels = c("X0", "X1")),
                positive = "X1")
```

Again the logreg model seems to have less variance than its base models.

### EVAL: Stacked Model

A meta learner will make the final decision based on the model predictions, a 
boosted  decision tree model was used as the meta learner. 

First a test data set was prepared for the meta learner by combining
predictions on the validation set with the true labels.

```{r EVAL.STACK.predict, echo = FALSE}
Tree.test <- Ensemble.model(tree.models, df.test3)
Forest.test <- Ensemble.model(forest.models, df.test3)
Logreg.test <- Ensemble.model(logreg.models, df.test3)

# Build the final stacked test set
final.meta.input <- data.frame(
  tree   = ifelse(Tree.test == "X1", 1, 0),
  forest = ifelse(Forest.test == "X1", 1, 0),
  logreg = ifelse(Logreg.test == "X1", 1, 0),
  CLASS  = factor(ifelse(df.test3$CLASS == "X1", "X1", "X0"),
                  levels = c("X0", "X1"))
)
```

Then training parameters for the stacked model were defined with 5 fold 
validation, repeating use of F1 staistic as the training metric.

```{r EVAL.STACK.trncntrl, echo = FALSE}
stack.cntrl <-  trainControl(method = "cv", number = 5, savePredictions = "final",
                             classProbs = TRUE, summaryFunction = prSummary,
                             seeds = seeds, verboseIter = FALSE)
```


A function that passes the training data and the models was written. The
models are passed to the ensemble model function and their predictions 
stored in a dataframe with the true labels. This functions as the training
set for the meta model.

The meta model selected the meta learner was selected as a a strong blaance between
handling variance and bias.


```{r EVAL.Stacked.func, echo = FALSE}
METAMOD <- function(train.data, tree.models, forest.models, logreg.models) {
  
  # get predictions for training
  tree.train   <- Ensemble.model(tree.models, train.data)
  forest.train <- Ensemble.model(forest.models, train.data)
  logreg.train <- Ensemble.model(logreg.models, train.data)

  # put in dataframe
  meta.train <- data.frame(
    tree   = ifelse(tree.train == "X1", 1, 0),
    forest = ifelse(forest.train == "X1", 1, 0),
    logreg = ifelse(logreg.train == "X1", 1, 0),
    CLASS  = factor(ifelse(train.data$CLASS == "X1", "X1", "X0"),
                    levels = c("X0", "X1"))
  )
  
  # Train stacked model
  METAMOD <- tree.final <- train(
  CLASS ~.,
  data = meta.train,
  method = "xgbTree",
  trControl = stack.cntrl,
  metric = "F"
)

  return(METAMOD)
}
```

Now the model will be called and predictions made with the best threshold decided
by using the ROC method shown earlier.

```{r EVAL.meta.predict, echo = FALSE, message = FALSE}
STACKED.mod<- METAMOD(meta.test, tree.models, forest.models, logreg.models)

# Get predictions
meta.preds <- predict(STACKED.mod, newdata = final.meta.input, type = "prob")[,"X1"]

# get best threshold
meta.ROC <- roc(df.test3$CLASS, meta.preds)
threshold <- coords(meta.ROC, "best", transpose = FALSE)$threshold
meta.class <- ifelse(meta.preds > threshold	, "1", "0")
meta.class <- factor(meta.class, levels = c("0", "1"))

confusionMatrix(factor(meta.class, levels = c("0", "1")),
                       factor(df.test3$CLASS, levels = c("0", "1")),
                       positive = "1")
```

The stacked model has the highest balanced accuracy of all models, and an 
excellent sensitivity compared to the rest. Given the projects primary goal of
helping researchers identify variants with conflicting status this is an acceptable
trade-off.


```{r Metamodel.F1, echo = FALSE}

meta.f1 <- f1(meta.class, df.test3$CLASS )


F1.table <- rbind(F1.Base,
                  MetaModel = meta.f1)

knitr::kable(round(F1.table,2))
```

By F1 score alone the model doesn't out perform the other models. When 
the balanced accuracy, and general robustness of the model is considered it gains
significant ground in terms of quality.

```{r EVAL.Metamodel.ROC, message=FALSE, echo = FALSE}
meta.ROC <- roc(df.test3$CLASS, meta.preds)

plot(roc.xgb, col = "red", legacy.axes = TRUE)
plot(roc.forest, col="green", add= TRUE)
plot(roc.logreg, col = "blue", add = TRUE)
plot(meta.ROC, col = "black", add = TRUE)
title(main = "Comparison of Base model ROC's and Stacked Model ROC", line = 2.5)
```

From the ROC comparison to the base learners, we can see that it generally 
performs on par with the tree based models, though the glmnet seems to drag its
overall performance down some.

## Conclusion

The stacked model is the most robust model for detecting conflicting sentiment
towards a variant in the ClinVar database. It provides a comparable F1 score to 
sub models, and better balanced accuracy. Most importantly, it accomplishes this
*without* any of the tradeoffs the base models suffered from regarding sensitivity
and specificity.

```{r CONCLUSION.table, echo = FALSE}

F1.conc <- c(meta.f1, tree.f1, forest.f1, logreg.f1)
Sensitivity.conc <- c(0.76, 0.74, 0.61, 0.87)
Specificity.conc <- c(0.69, 0.70, 0.81, 0.46)
Balanced.Accuracy.conc <- c(0.72, 0.72, 0.71, 0.66)

conc.table <- cbind(F1= round(F1.conc, 2),
                    Sensitivity = Sensitivity.conc,
                    Specificity = Specificity.conc,
                    `Balanced Accuracy` = Balanced.Accuracy.conc)
row.names(conc.table) <- c("Meta Model", "Tree Model", "Forest Model",
                            "Logistic Reg.")

knitr::kable(conc.table)
```


Though the reported F1 score of `r meta.f1` and other statistics may be considered
poor in a general sense, when considered in the context of the data, and compared 
to  previous work done the model is a top contender.

While the model is not entirely suitable for clinical researchers or medical 
applications,it can serve as a tool for researchers during the discovery phase 
of a new project, or in conjunction with other methods.

Suggested future improvements include removing or replacing the glmnet model in
the stack with something more robust. More robust feature engineering such as 
annotating transitions and transversions, identifying amino acid changes that 
result in major structural changes relative to the original such as alanine to
phenylalanine.
